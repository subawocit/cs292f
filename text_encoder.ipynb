{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f06a7f6-3e75-4dcb-9734-434b8f3a2438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd/yuchen\n"
     ]
    }
   ],
   "source": [
    "%cd /hdd/yuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "179dba1a-8bd2-4802-9133-887257690330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import clip\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from matplotlib.pyplot import imshow\n",
    "import torchtext\n",
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams\n",
    "import collections\n",
    "import scipy \n",
    "import IProgress \n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "%matplotlib inline\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4409ad10-cfe1-49f3-8db4-3c23133e5b94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bebdbcdec904a4c803e26101f039dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "featname = 'c'\n",
    "use_stim = 'each'\n",
    "\n",
    "subject= 'subj01'\n",
    "use_stim = 'each'\n",
    "topdir = '/hdd/yuchen/nsdfeat'\n",
    "\n",
    "savedir = f'{topdir}/subjfeat/'\n",
    "featdir = f'{topdir}/15dim/{featname}/'\n",
    "\n",
    "nsd_expdesign = scipy.io.loadmat('/hdd/yuchen/nsd/nsddata/experiments/nsd/nsd_expdesign.mat')\n",
    "\n",
    "# Note that most of them are 1-base index!\n",
    "sharedix = nsd_expdesign['sharedix'] -1 \n",
    "stims = np.load(f'/hdd/yuchen/mrifeat/{subject}/{subject}_stims.npy')\n",
    "\n",
    "feats = []\n",
    "tr_idx = np.zeros(len(stims))\n",
    "\n",
    "ct = 0\n",
    "\n",
    "for idx, s in tqdm(enumerate(stims)): \n",
    "    if s in sharedix:\n",
    "        tr_idx[idx] = 0\n",
    "    else:\n",
    "        tr_idx[idx] = 1    \n",
    "    if os.path.exists(f'{featdir}/{s:06}.npy'):\n",
    "        feat = np.load(f'{featdir}/{s:06}.npy')\n",
    "        feats.append(feat)\n",
    "    else: \n",
    "        # print(f'{s:06}.npy does not exist')\n",
    "        feats.append(np.array([0]*768*15))\n",
    "        ct += 1\n",
    "\n",
    "feats = np.stack(feats)    \n",
    "\n",
    "feats_tr = feats[tr_idx==1]\n",
    "feats_te = feats[tr_idx==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b714770b-44f6-445d-bd03-d42d04f39370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24980, 11520), (2770, 11520))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_tr.shape, feats_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625d7678-883f-4b30-b8b9-8f1e64b465f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = '/hdd/yuchen/mrifeat/subj01/'\n",
    "\n",
    "betas_tr = np.load(f'{savedir}/{subject}_ventral_betas_tr.npy')\n",
    "betas_te = np.load(f'{savedir}/{subject}_ventral_betas_te.npy')\n",
    "betas_tr_avg = np.load(f'{savedir}/{subject}_ventral_betas_ave_tr.npy')\n",
    "betas_te_avg = np.load(f'{savedir}/{subject}_ventral_betas_ave_te.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f061d98-5e37-4f50-9b90-eccdb12f4fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24980, 7604), (2770, 7604))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas_tr.shape, betas_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7aa083ff-55f4-4cd2-93a9-f8ee4b3aa387",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_idx = np.where(np.mean(feats_tr,axis=1) == 0.0)[0]\n",
    "mask = np.ones(len(feats_tr), dtype=bool) \n",
    "mask[empty_idx] = False  \n",
    "feats_tr = feats_tr[mask]\n",
    "betas_tr = betas_tr[mask]\n",
    "\n",
    "empty_idx = np.where(np.mean(feats_te,axis=1) == 0.0)[0]\n",
    "mask = np.ones(len(feats_te), dtype=bool) \n",
    "mask[empty_idx] = False  \n",
    "feats_te = feats_te[mask]\n",
    "betas_te = betas_te[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "883e5f8b-cecc-4292-9f1c-9025fedc5323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e3c6b8c45740d09304e60df67e6454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stims = np.load(f'/hdd/yuchen/mrifeat/{subject}/{subject}_stims_ave.npy')\n",
    "\n",
    "feats_avg = []\n",
    "tr_idx = np.zeros(len(stims))\n",
    "\n",
    "ct = 0\n",
    "\n",
    "for idx, s in tqdm(enumerate(stims)): \n",
    "    if s in sharedix:\n",
    "        tr_idx[idx] = 0\n",
    "    else:\n",
    "        tr_idx[idx] = 1    \n",
    "    if os.path.exists(f'{featdir}/{s:06}.npy'):\n",
    "        # feat = np.load(f'{featdir}/{s:06}.npy')[0]\n",
    "        feat = np.load(f'{featdir}/{s:06}.npy')\n",
    "        \n",
    "        feats_avg.append(feat)\n",
    "    else: \n",
    "        # print(f'{s:06}.npy does not exist')\n",
    "        # feats_avg.append('empty')\n",
    "        feats_avg.append(np.array([0]*768*15))\n",
    "        ct += 1\n",
    "\n",
    "feats_avg = np.stack(feats_avg)    \n",
    "\n",
    "feats_tr_avg = feats_avg[tr_idx==1]\n",
    "feats_te_avg = feats_avg[tr_idx==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e60c166d-9d42-42ee-b8cd-10325a637458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8859, 11520), (982, 11520))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_tr_avg.shape, feats_te_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af359c6c-16c9-4cc3-921f-ca1678bbd4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_idx = np.where(np.mean(feats_tr_avg,axis=1) == 0.0)[0]\n",
    "mask = np.ones(len(feats_tr_avg), dtype=bool) \n",
    "mask[empty_idx] = False  \n",
    "feats_tr_avg = feats_tr_avg[mask]\n",
    "betas_tr_avg = betas_tr_avg[mask]\n",
    "\n",
    "empty_idx = np.where(np.mean(feats_te_avg,axis=1) == 0.0)[0]\n",
    "mask = np.ones(len(feats_te_avg), dtype=bool) \n",
    "mask[empty_idx] = False  \n",
    "feats_te_avg = feats_te_avg[mask]\n",
    "betas_te_avg = betas_te_avg[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62d3bf8e-668d-44d5-a02d-82bc7c9e4fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8859, 11520), (982, 11520), (8859, 7604), (982, 7604))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_tr_avg.shape, feats_te_avg.shape, betas_tr_avg.shape, betas_te_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26dca3e4-11d6-48e0-aea8-6c29d33a5b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24980, 11520), (24980, 7604))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_tr.shape, betas_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba35f73-782d-4964-8c41-6d58f5cce4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "307782b1-49c0-449d-bcf7-be0fcf3f89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os\n",
    "import numpy as np\n",
    "from himalaya.backend import set_backend\n",
    "from himalaya.ridge import RidgeCV\n",
    "from himalaya.scoring import correlation_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c7b395df-80e5-409a-9475-6d924d5bb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.000001,0.00001,0.0001,0.001,0.01, 0.1, 1]\n",
    "\n",
    "ridge = RidgeCV(alphas=alpha)\n",
    "\n",
    "preprocess_pipeline = make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "    )\n",
    "pipeline = make_pipeline(\n",
    "        preprocess_pipeline,\n",
    "        ridge,\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "7045c8c0-a798-4b6f-b90d-d485b1100030",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = betas_tr\n",
    "Y = feats_tr\n",
    "X_te = betas_te_avg\n",
    "pipeline.fit(X, Y)\n",
    "scores = pipeline.predict(X_te)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(scores,feats_te_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "863ea6e2-1123-496f-85b9-a7d326106f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7283405637940131"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2e889-c70e-4cdb-b086-7b858021183d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "809ae3a4-ff68-4923-8bbe-25ececadc0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, betas, feats):\n",
    "        betas = (betas - betas.mean()) / betas.std()\n",
    "        self.betas = torch.tensor(betas, dtype=torch.float32)\n",
    "        feats = feats.reshape(-1,15,768)\n",
    "        feats = feats[:,1:,:].reshape(-1,14*768)\n",
    "        self.feats = torch.tensor(feats, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.betas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'betas': self.betas[idx], 'feats': self.feats[idx]}\n",
    "\n",
    "train_dataset = CustomDataset(betas_tr, feats_tr)\n",
    "test_dataset = CustomDataset(betas_te_avg, feats_te_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "409ca042-3961-46c0-ba9d-7d90901c99e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = feats_tr[0,:768]\n",
    "cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b083bcd-7646-474c-814b-f250d343d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16  \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "num_neurons = batch['betas'].shape[-1]\n",
    "num_features = batch['feats'].shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b93ccf-0dbb-4a57-94e4-86f5a0fb0169",
   "metadata": {},
   "source": [
    "## original text encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79ecd8a0-750c-4f2e-bf02-dbec0a63698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_neurons, num_features):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "        channel = 64\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(1, channel, kernel_size=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(channel, channel, kernel_size=7, padding = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(channel, channel, kernel_size=7, padding = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(channel, channel, kernel_size=7, padding=3),\n",
    "        )\n",
    "\n",
    "        self.downsample = nn.Conv1d(channel, 1, kernel_size=1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_neurons, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, 14*768)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        for i in range(3):\n",
    "            x = x + self.net(x)\n",
    "        x = self.downsample(x)\n",
    "        x = x.reshape(-1, self.num_neurons)\n",
    "        x = self.fc(x)\n",
    "        # x = x.reshape(-1, 14, 768)\n",
    "        # x = x.reshape(-1, 14*768)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a8b88d6-3bb7-4663-8de4-2279dcf90e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] train loss 0.32772 val loss 0.31585\n",
      "[epoch 1] train loss 0.29593 val loss 0.29396\n",
      "[epoch 2] train loss 0.28134 val loss 0.27687\n",
      "[epoch 3] train loss 0.26775 val loss 0.27569\n",
      "[epoch 4] train loss 0.25213 val loss 0.26719\n",
      "[epoch 5] train loss 0.23392 val loss 0.26564\n",
      "[epoch 6] train loss 0.21524 val loss 0.26937\n",
      "[epoch 7] train loss 0.19865 val loss 0.26884\n",
      "[epoch 8] train loss 0.18486 val loss 0.27259\n",
      "[epoch 9] train loss 0.17349 val loss 0.27485\n",
      "[epoch 10] train loss 0.16427 val loss 0.2737\n",
      "[epoch 11] train loss 0.15627 val loss 0.27388\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:1'\n",
    "model = NeuralNetwork(num_neurons = num_neurons, num_features = num_features).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 5\n",
    "ct = 0\n",
    "best_loss_val = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss_train = 0\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        betas = batch['betas'].to(device).unsqueeze(1)\n",
    "        feats = batch['feats'].to(device)\n",
    "        \n",
    "        pred = model(betas)\n",
    "        loss = loss_fn(pred, feats)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss_train += loss.item()\n",
    "    print('[epoch {}] train loss {}'.format(epoch, round(total_loss_train/len(train_dataloader), 5)), end = ' ')\n",
    "\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            betas = batch['betas'].to(device).unsqueeze(1)\n",
    "            feats = batch['feats'].to(device)\n",
    "            pred = model(betas)\n",
    "            loss = loss_fn(pred, feats)\n",
    "            total_loss_val += loss.item()\n",
    "        total_loss_val = total_loss_val/len(test_dataloader)\n",
    "        print('val loss {}'.format(round(total_loss_val, 5)))\n",
    "        \n",
    "        if total_loss_val < best_loss_val:\n",
    "            ct = 0\n",
    "            best_loss_val = total_loss_val\n",
    "            torch.save(model.state_dict(), '/hdd/yuchen/modelweights.pth')\n",
    "        else:\n",
    "            ct += 1\n",
    "            if ct > patience:\n",
    "                print('end')\n",
    "                break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52f4fb29-bf0b-46e1-8a70-ca562ce96066",
   "metadata": {},
   "source": [
    "hidden_dim = 512 0.29659\n",
    "hidden_dim = 1024 0.29241\n",
    "hidden_dim = 1024&512: 0.29075\n",
    "hidden_dim = 512&1024: 0.29001\n",
    "hidden_dim = 512&768: 0.29064\n",
    "\n",
    "2 net: 0.29603\n",
    "4 net: 0.29037\n",
    "\n",
    "14 token non_parallel 512: 0.2919\n",
    "14 token non_parallel 1024&512: 0.28712\n",
    "14 token non_parallel 512&1024: 0.28341\n",
    "14 token non_parallel 512&2048: 0.28119\n",
    "14 token non_parallel 1024&4096: 0.27796\n",
    "14 token non_parallel 1024&2048: 0.27204\n",
    "14 token non_parallel 2048&2048: bad\n",
    "\n",
    "GELU in self.fc: 0.27484\n",
    "\n",
    "channel=32: 0.28117\n",
    "channel=128: 0.27762\n",
    "\n",
    "14 token non_parallel 1024&2048; channel=64; 3net:\n",
    "    double downsample with relu in between 64&16: 0.27767\n",
    "    re-run on a larger sample size: 0.27919\n",
    "        no downsample: 0.31475\n",
    "        kernal5padding2: 0.27438\n",
    "        kernal11padding5: 0.27319\n",
    "        kernal11,7,7: 0.27785\n",
    "        kernal5,7,7: 0.27887\n",
    "        batch norm after relu: 0.27422\n",
    "            before relu: 0.27347\n",
    "        kernal7padding3: 0.27257\n",
    "            including last layer: 0.2715\n",
    "                lr=0.005: bad; lr=0.0005: 0.2751; lr=0.00005: 0.2734\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a57b9-35dc-43fb-a392-9b1748216229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68892b2b-fcdb-46ce-b65d-a77b9da0a445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/hdd/yuchen/modelweights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9ec9eb8-904e-4112-bdca-1464fcaa07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "lst_gt = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        betas = batch['betas'].to(device).unsqueeze(1)\n",
    "        feats = batch['feats'].to(device)\n",
    "        pred = model(betas)\n",
    "        lst.append(pred.cpu().detach().numpy())\n",
    "        lst_gt.append(feats.cpu().detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc6af548-e86e-49e5-840d-c59f805bee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = np.vstack(lst)\n",
    "lst_gt = np.vstack(lst_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dc0459f-b0b9-4b36-94dc-779ea643c4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26555938"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(lst,lst_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a9ac4-766b-4f19-8e79-111257bfe8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bcf447c-62e5-4676-97ea-72133eb1eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = lst.reshape(-1, 14, 768)\n",
    "lst_gt = lst_gt.reshape(-1, 14, 768)\n",
    "cls_ = np.tile(cls, (982, 1))\n",
    "cls_ = np.expand_dims(cls_, 1)\n",
    "lst = np.concatenate((cls_, lst), axis=1)\n",
    "lst_gt = np.concatenate((cls_, lst_gt), axis=1)\n",
    "np.save('/hdd/yuchen/temp_lst.npy', lst)\n",
    "np.save('/hdd/yuchen/temp_lst_gt.npy', lst_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45451b67-a685-4fee-b474-ecf31bf9d85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e453f682-e9d9-4bc3-a993-82d2e000db90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561920e4-f6fa-49b8-a99a-c82db767801c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7c57d-9dbc-4456-b05d-93a32e17ab3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699e8484-259a-4dcc-ba90-141851204750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ba71a-4212-4ce6-8256-e00325a1ef14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
