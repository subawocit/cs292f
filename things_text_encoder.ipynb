{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f06a7f6-3e75-4dcb-9734-434b8f3a2438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hdd/yuchen\n"
     ]
    }
   ],
   "source": [
    "%cd /hdd/yuchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "179dba1a-8bd2-4802-9133-887257690330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import clip\n",
    "from torch.utils.data import Dataset, DataLoader, BatchSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "from matplotlib.pyplot import imshow\n",
    "import torchtext\n",
    "import nltk, re, string, collections\n",
    "from nltk.util import ngrams\n",
    "import collections\n",
    "import scipy \n",
    "import IProgress \n",
    "from ipywidgets import FloatProgress\n",
    "\n",
    "%matplotlib inline\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92225b4-d681-4d31-976e-756645e71d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4409ad10-cfe1-49f3-8db4-3c23133e5b94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = '/hdd/yuchen/cs292/test/nsdfeat/c/'\n",
    "files = glob.glob(save_dir + '*')\n",
    "t = [int(f.split('/')[-1].split('.')[0]) for f in files]\n",
    "t.sort()\n",
    "feats_te_avg = []\n",
    "for file_idx in t: feats_te_avg.append(np.load(f'{save_dir}{file_idx:06}.npy'))\n",
    "feats_te_avg = np.array(feats_te_avg)\n",
    "\n",
    "save_dir = '/hdd/yuchen/cs292/train/nsdfeat/c/'\n",
    "files = glob.glob(save_dir + '*')\n",
    "t = [int(f.split('/')[-1].split('.')[0]) for f in files]\n",
    "t.sort()\n",
    "feats_tr = []\n",
    "for file_idx in t: feats_tr.append(np.load(f'{save_dir}{file_idx:06}.npy'))\n",
    "feats_tr = np.array(feats_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b714770b-44f6-445d-bd03-d42d04f39370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8640, 11520), (100, 11520))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_tr.shape, feats_te_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce11292b-409d-4425-b42f-636f1b5aa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "\n",
    "betas_csv_dir = '/hdd/yuchen/cs292/fmri/betas_csv/'\n",
    "sub = '01'\n",
    "    \n",
    "data_file = pjoin(betas_csv_dir, f'sub-{sub}_ResponseData.h5')\n",
    "responses = pd.read_hdf(data_file)\n",
    "vox_f = pjoin(betas_csv_dir, f'sub-{sub}_VoxelMetadata.csv')\n",
    "voxdata = pd.read_csv(vox_f)\n",
    "stim_f = pjoin(betas_csv_dir, f'sub-{sub}_StimulusMetadata.csv')\n",
    "stimdata = pd.read_csv(stim_f)\n",
    "\n",
    "train_idx = stimdata[stimdata['trial_type'] == 'train'].index.tolist()\n",
    "test_idx = stimdata[stimdata['trial_type'] == 'test'].index.tolist()\n",
    "    \n",
    "train_fmri = responses[train_idx]\n",
    "test_fmri = responses[test_idx]\n",
    "    \n",
    "train_labels = stimdata[stimdata['trial_type'] == 'train']['stimulus']\n",
    "test_labels = stimdata[stimdata['trial_type'] == 'test']['stimulus']\n",
    "    \n",
    "roi_idx = voxdata[(voxdata['lFFA'] == 1) ]['voxel_id'].tolist()\n",
    "train_fmri_temp = train_fmri.iloc[roi_idx]\n",
    "test_fmri_temp = test_fmri.iloc[roi_idx]\n",
    "\n",
    "roi_neuron = {'lFFA': train_fmri_temp.shape[0]}\n",
    "for roi in ['VO1', 'VO2', 'TO1', 'TO2',\n",
    "    'rFFA', 'lPPA', 'rPPA', \n",
    "             'lLOC', 'rLOC']:\n",
    "    roi_idx = voxdata[(voxdata[roi] == 1)]['voxel_id'].tolist()\n",
    "    train_fmri_temp = pd.concat([train_fmri_temp, train_fmri.iloc[roi_idx]])\n",
    "    test_fmri_temp = pd.concat([test_fmri_temp, test_fmri.iloc[roi_idx]])\n",
    "    roi_neuron[roi] = train_fmri.iloc[roi_idx].shape[0]\n",
    "    \n",
    "train_fmri = train_fmri_temp\n",
    "test_fmri = test_fmri_temp\n",
    "\n",
    "test = stimdata[stimdata['trial_type'] == 'test']\n",
    "test_fmri_avg = []\n",
    "test_labels = test['stimulus'].unique()\n",
    "for stim in test_labels:\n",
    "    repeated_trial = test[test['stimulus'] == stim].index.tolist()\n",
    "    test_fmri_avg.append(test_fmri[repeated_trial].mean(axis=1).to_numpy())\n",
    "test_fmri_avg = np.array(test_fmri_avg)\n",
    "\n",
    "del responses, voxdata, stimdata\n",
    "# train_fmri, test_fmri =  train_fmri.to_numpy(), test_fmri.to_numpy()\n",
    "train_img_label_all, test_img_label_all = train_labels.tolist(), test_labels.tolist()\n",
    "\n",
    "betas_tr = train_fmri.T\n",
    "betas_te_avg = test_fmri_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed2870d-e5e9-4159-8ff4-f3ff22029b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lFFA': 154,\n",
       " 'VO1': 287,\n",
       " 'VO2': 149,\n",
       " 'TO1': 369,\n",
       " 'TO2': 316,\n",
       " 'rFFA': 399,\n",
       " 'lPPA': 395,\n",
       " 'rPPA': 414,\n",
       " 'lLOC': 1573,\n",
       " 'rLOC': 1127}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba35f73-782d-4964-8c41-6d58f5cce4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_tr (8640, 11520)\n",
      "betas_tr (8640, 5183)\n",
      "feats_te_avg (100, 11520)\n",
      "betas_te_avg (100, 5183)\n"
     ]
    }
   ],
   "source": [
    "print('feats_tr', feats_tr.shape)\n",
    "print('betas_tr', betas_tr.shape)\n",
    "\n",
    "print('feats_te_avg', feats_te_avg.shape)\n",
    "print('betas_te_avg', betas_te_avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247db993-458b-4abf-898e-2d972eb911f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_tr = np.array(betas_tr)\n",
    "betas_te_avg = np.array(betas_te_avg)\n",
    "\n",
    "betas_tr_ = ((betas_tr - betas_tr.mean()) / betas_tr.std())\n",
    "betas_te_avg_ = ((betas_te_avg - betas_te_avg.mean()) / betas_te_avg.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b514da-d53c-48fa-a0d3-4b57f4bc9810",
   "metadata": {},
   "source": [
    "## baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307782b1-49c0-449d-bcf7-be0fcf3f89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os\n",
    "import numpy as np\n",
    "from himalaya.backend import set_backend\n",
    "from himalaya.ridge import RidgeCV\n",
    "from himalaya.scoring import correlation_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7b395df-80e5-409a-9475-6d924d5bb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.000001,0.00001,0.0001,0.001,0.01, 0.1, 1]\n",
    "\n",
    "ridge = RidgeCV(alphas=alpha)\n",
    "\n",
    "preprocess_pipeline = make_pipeline(\n",
    "        StandardScaler(with_mean=True, with_std=True),\n",
    "    )\n",
    "pipeline = make_pipeline(\n",
    "        preprocess_pipeline,\n",
    "        ridge,\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7045c8c0-a798-4b6f-b90d-d485b1100030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1444197"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = betas_tr\n",
    "Y = feats_tr\n",
    "X_te = betas_te_avg\n",
    "pipeline.fit(X, Y)\n",
    "scores = pipeline.predict(X_te)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(scores,feats_te_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "863ea6e2-1123-496f-85b9-a7d326106f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/hdd/yuchen/things_baseline_c.npy',scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e2dd22-53a4-4946-8c2c-9d30cc02bf8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73b93ccf-0dbb-4a57-94e4-86f5a0fb0169",
   "metadata": {},
   "source": [
    "## text encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "32b6f2ce-2e0d-4d2a-8db1-7c02183ff10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_tr = betas_tr_\n",
    "betas_te_avg = betas_te_avg_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5c450ae7-01fa-4565-8422-ded4eff0c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, betas, feats):\n",
    "        betas = (betas - betas.mean()) / betas.std()\n",
    "        self.betas = torch.tensor(betas, dtype=torch.float32)\n",
    "        feats = feats.reshape(-1,15,768)\n",
    "        feats = feats[:,1:,:].reshape(-1,14*768)\n",
    "        self.feats = torch.tensor(feats, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.betas)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'betas': self.betas[idx], 'feats': self.feats[idx]}\n",
    "\n",
    "train_dataset = CustomDataset(betas_tr, feats_tr)\n",
    "test_dataset = CustomDataset(betas_te_avg, feats_te_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e27d9d23-41f2-49c3-a4b6-093256e575fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = feats_tr[0,:768]\n",
    "cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "66300839-f3f9-486d-8696-e9e1f7931bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256  \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    break\n",
    "num_neurons = batch['betas'].shape[-1]\n",
    "num_features = batch['feats'].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "79ecd8a0-750c-4f2e-bf02-dbec0a63698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_neurons, num_features):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.num_neurons = num_neurons\n",
    "        channel = 16\n",
    "        \n",
    "        self.conv1d = nn.Conv1d(1, channel, kernel_size=1)\n",
    "        self.relu = nn.GELU()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(channel, channel, kernel_size=5, padding = 2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv1d(channel, channel, kernel_size=5, padding = 2),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Conv1d(channel, channel, kernel_size=7, padding=3),\n",
    "        )\n",
    "\n",
    "        self.downsample = nn.Conv1d(channel, 1, kernel_size=1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_neurons, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, 14*768)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1d(x)\n",
    "        for i in range(2):\n",
    "            x = x + self.net(x)\n",
    "        x = self.downsample(x)\n",
    "        x = x.reshape(-1, self.num_neurons)\n",
    "        x = self.fc(x)\n",
    "        # x = x.reshape(-1, 14, 768)\n",
    "        # x = x.reshape(-1, 14*768)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1a8b88d6-3bb7-4663-8de4-2279dcf90e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] train loss 0.88893 val loss 0.82011\n",
      "[epoch 1] train loss 0.81071 val loss 0.80555\n",
      "[epoch 2] train loss 0.80685 val loss 0.80564\n",
      "[epoch 3] train loss 0.8066 val loss 0.80494\n",
      "[epoch 4] train loss 0.80609 val loss 0.80394\n",
      "[epoch 5] train loss 0.80337 val loss 0.80133\n",
      "[epoch 6] train loss 0.79876 val loss 0.79701\n",
      "[epoch 7] train loss 0.79285 val loss 0.79745\n",
      "[epoch 8] train loss 0.78576 val loss 0.79409\n",
      "[epoch 9] train loss 0.77616 val loss 0.80126\n",
      "[epoch 10] train loss 0.76243 val loss 0.80372\n",
      "[epoch 11] train loss 0.74555 val loss 0.81167\n",
      "[epoch 12] train loss 0.72652 val loss 0.82275\n",
      "[epoch 13] train loss 0.70805 val loss 0.8273\n",
      "[epoch 14] train loss 0.68966 val loss 0.838\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "# device = 'cuda:1'\n",
    "# model = NeuralNetwork(num_neurons = num_neurons, num_features = num_features).to(device)\n",
    "device = 'cuda:1'\n",
    "model = NeuralNetwork(num_neurons = num_neurons, num_features = num_features).to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 5\n",
    "ct = 0\n",
    "best_loss_val = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss_train = 0\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        betas = batch['betas'].to(device).unsqueeze(1)\n",
    "        feats = batch['feats'].to(device)\n",
    "        \n",
    "        pred = model(betas)\n",
    "        loss = loss_fn(pred, feats)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss_train += loss.item()\n",
    "    print('[epoch {}] train loss {}'.format(epoch, round(total_loss_train/len(train_dataloader), 5)), end = ' ')\n",
    "\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            betas = batch['betas'].to(device).unsqueeze(1)\n",
    "            feats = batch['feats'].to(device)\n",
    "            pred = model(betas)\n",
    "            loss = loss_fn(pred, feats)\n",
    "            total_loss_val += loss.item()\n",
    "        total_loss_val = total_loss_val/len(test_dataloader)\n",
    "        print('val loss {}'.format(round(total_loss_val, 5)))\n",
    "        \n",
    "        if total_loss_val < best_loss_val:\n",
    "            ct = 0\n",
    "            best_loss_val = total_loss_val\n",
    "            torch.save(model.state_dict(), '/hdd/yuchen/modelweights_things_text.pth')\n",
    "        else:\n",
    "            ct += 1\n",
    "            if ct > patience:\n",
    "                print('end')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "68892b2b-fcdb-46ce-b65d-a77b9da0a445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('/hdd/yuchen/modelweights_things_text.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f9ec9eb8-904e-4112-bdca-1464fcaa07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = []\n",
    "lst_gt = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataloader:\n",
    "        betas = batch['betas'].to(device).unsqueeze(1)\n",
    "        feats = batch['feats'].to(device)\n",
    "        pred = model(betas)\n",
    "        lst.append(pred.cpu().detach().numpy())\n",
    "        lst_gt.append(feats.cpu().detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "275139fd-ae01-42d1-a3c9-ee6b907a15c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3499, -0.1562,  0.7644,  ..., -0.7600,  0.3453, -0.2395]],\n",
       "        device='cuda:1', grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.2328,  0.0244,  0.9604,  ..., -1.3347,  0.1941, -0.0092]],\n",
       "        device='cuda:1', grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = NeuralNetwork(num_neurons = num_neurons, num_features = num_features).to(device)\n",
    "# model.load_state_dict(torch.load('/hdd/yuchen/modelweights_things_text.pth'))\n",
    "\n",
    "model(betas[0].unsqueeze(0)),model(betas[1].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bc6af548-e86e-49e5-840d-c59f805bee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = np.vstack(lst)\n",
    "lst_gt = np.vstack(lst_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a9de06de-e5cb-4052-8b10-8ab5d341deca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71181595, 0.73505664, 0.71364105, 0.7019855 , 0.6923032 ,\n",
       "       0.7086132 , 0.70836276, 0.71297467, 0.7156067 , 0.6969159 ,\n",
       "       0.6972205 , 0.70788664, 0.7077007 , 0.69142467, 0.68474114,\n",
       "       0.6840819 , 0.6620259 , 0.6996463 , 0.71602154, 0.70522964,\n",
       "       0.68986654, 0.66479784, 0.69160914, 0.6791347 , 0.7234187 ,\n",
       "       0.6783101 , 0.7398947 , 0.72037697, 0.7183888 , 0.6974153 ,\n",
       "       0.7209481 , 0.69500875, 0.6957981 , 0.6610886 , 0.65416306,\n",
       "       0.70891315, 0.69346607, 0.6644432 , 0.7043479 , 0.7353466 ,\n",
       "       0.7088088 , 0.72232044, 0.71578294, 0.68431884, 0.729495  ,\n",
       "       0.6841668 , 0.6926066 , 0.6670073 , 0.6673077 , 0.6835449 ,\n",
       "       0.6722989 , 0.7120063 , 0.7248988 , 0.6671987 , 0.6959851 ,\n",
       "       0.68645775, 0.67412615, 0.6631919 , 0.68711895, 0.71583396,\n",
       "       0.68420607, 0.7136631 , 0.7173392 , 0.69759357, 0.6986996 ,\n",
       "       0.6791419 , 0.722405  , 0.7063052 , 0.733666  , 0.68310744,\n",
       "       0.6859597 , 0.7399479 , 0.7266967 , 0.7144546 , 0.7240401 ,\n",
       "       0.69342977, 0.7110714 , 0.6752141 , 0.67649776, 0.6588681 ,\n",
       "       0.65168685, 0.69132215, 0.72744673, 0.68699944, 0.7097909 ,\n",
       "       0.67911303, 0.708011  , 0.7186901 , 0.6707177 , 0.7072216 ,\n",
       "       0.7023532 , 0.70322895, 0.73977673, 0.68067235, 0.7107931 ,\n",
       "       0.6880075 , 0.7018344 , 0.7369655 , 0.72121567, 0.69456553],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(lst-lst_gt),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6dc0459f-b0b9-4b36-94dc-779ea643c4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794091"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(lst,lst_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a9ac4-766b-4f19-8e79-111257bfe8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "3bcf447c-62e5-4676-97ea-72133eb1eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = lst.reshape(-1, 14, 768)\n",
    "lst_gt = lst_gt.reshape(-1, 14, 768)\n",
    "cls_ = np.tile(cls, (100, 1))\n",
    "cls_ = np.expand_dims(cls_, 1)\n",
    "lst = np.concatenate((cls_, lst), axis=1)\n",
    "lst_gt = np.concatenate((cls_, lst_gt), axis=1)\n",
    "# np.save('/hdd/yuchen/things_temp_lst_c.npy', lst)\n",
    "np.save('/hdd/yuchen/things_temp_lst_c_again.npy', lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e453f682-e9d9-4bc3-a993-82d2e000db90",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/hdd/yuchen/things_temp_lst_c_again_gt.npy', lst_gt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e830a726-11d3-48e2-82a4-224b287868dd",
   "metadata": {},
   "source": [
    "## roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "59adc796-dde8-43aa-a016-7ed6cc25f4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(roi_neuron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4fe7c57d-9dbc-4456-b05d-93a32e17ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_tr_temp = betas_tr_[:, :roi_neuron['lFFA']]\n",
    "num_feature = 1573\n",
    "zeros = np.zeros((betas_tr_temp.shape[0], num_feature))\n",
    "zeros[:, :betas_tr_temp.shape[-1]] = betas_tr_temp\n",
    "betas_tr_temp = zeros  # (8640, 1573)\n",
    "for roi in range(2, len(roi_neuron)+1):\n",
    "    temp = betas_tr_[:, sum(list(roi_neuron.values())[:roi-1]):sum(list(roi_neuron.values())[:roi])]\n",
    "    #     # if roi == 3: temp = betas_tr_[:, sum(list(roi_neuron.values())[:roi-1]):]\n",
    "    zeros = np.zeros((betas_tr_.shape[0], num_feature))\n",
    "    zeros[:, :temp.shape[-1]] = temp\n",
    "    betas_tr_temp = np.hstack([betas_tr_temp, zeros])\n",
    "\n",
    "betas_te_avg_temp = betas_te_avg_[:, :roi_neuron['lFFA']]\n",
    "zeros = np.zeros((betas_te_avg_temp.shape[0], num_feature))\n",
    "zeros[:, :betas_te_avg_temp.shape[-1]] = betas_te_avg_temp\n",
    "betas_te_avg_temp = zeros\n",
    "for roi in range(2, len(roi_neuron)+1):\n",
    "    temp = betas_te_avg_[:, sum(list(roi_neuron.values())[:roi-1]):sum(list(roi_neuron.values())[:roi])]\n",
    "    # if roi == 3: temp = betas_te_avg_[:, sum(list(roi_neuron.values())[:roi-1]):]\n",
    "    zeros = np.zeros((betas_te_avg_.shape[0], num_feature))\n",
    "    zeros[:, :temp.shape[-1]] = temp\n",
    "    betas_te_avg_temp = np.hstack([betas_te_avg_temp, zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "699e8484-259a-4dcc-ba90-141851204750",
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_tr_ = betas_tr_temp\n",
    "betas_te_avg_ = betas_te_avg_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "447c0226-710c-4d23-b250-21b304eb0d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8640, 25168)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas_tr_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "268ba71a-4212-4ce6-8256-e00325a1ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_roi = 16\n",
    "\n",
    "num_neurons = betas_tr_.shape[-1]\n",
    "num_pad = (num_neurons // num_roi + 1) * num_roi - num_neurons\n",
    "\n",
    "betas_tr = np.pad(betas_tr_, ((0, 0), (0, num_pad)), 'constant', constant_values=0)\n",
    "betas_te_avg = np.pad(betas_te_avg_, ((0, 0), (0, num_pad)), 'constant', constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6381d8c1-60a1-49e7-bf74-876b0f93acc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls = feats_tr[0,:768]\n",
    "cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "61de7b3d-85e1-4c89-b8d8-40796214e68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, BatchSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import nltk, re, string, collections\n",
    "import scipy \n",
    "import IProgress \n",
    "from ipywidgets import FloatProgress\n",
    "from nilearn import connectome\n",
    "from sklearn.preprocessing import Normalizer, OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, TopKPooling, BatchNorm, global_mean_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c64e40d5-0000-4695-bc8b-f7ef89748870",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd/yuchen/anaconda3/envs/ldm/lib/python3.8/site-packages/nilearn/connectome/connectivity_matrices.py:509: FutureWarning: The default strategy for standardize is currently 'zscore' which incorrectly uses population std to calculate sample zscores. The new strategy 'zscore_sample' corrects this behavior by using the sample std. In release 0.13, the default strategy will be replaced by the new strategy and the 'zscore' option will be removed. Please use 'zscore_sample' instead.\n",
      "  covariances_std = [\n"
     ]
    }
   ],
   "source": [
    "num_neurons_each_roi = int(betas_te_avg.shape[-1]/num_roi)\n",
    "\n",
    "conn_measure = connectome.ConnectivityMeasure(kind='correlation')\n",
    "\n",
    "function_con = betas_tr.reshape(-1, num_roi, num_neurons_each_roi)\n",
    "\n",
    "connectivity = conn_measure.fit_transform([np.mean(function_con, axis=-1)])\n",
    "for i in range(len(connectivity[0])):\n",
    "    connectivity[0][i, i] = 0  # setting the i-th row to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "8580aeb3-472a-43c9-bba6-867329f4f5ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 16, 16)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connectivity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2d4f4d80-afd3-4c7d-b40a-99dda3d3a2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 22)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjmatrix = np.where(abs(connectivity[0]) > 0.8)\n",
    "edge_index = np.array(adjmatrix)  # edge index matrix of shape [2, num_edges]\n",
    "\n",
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c1028b14-6145-4cbe-ae36-089f6c092255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_attr = []\n",
    "for idx in range(edge_index.shape[1]):\n",
    "    edge_attr.append(connectivity[0][edge_index[0,idx], edge_index[1,idx]])\n",
    "edge_attr = np.array(edge_attr)\n",
    "edge_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "901acc08-ba0d-44d5-9290-82fe0af92cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge_index_temp = []\n",
    "# edge_attr_temp = []\n",
    "# for i in range(edge_attr.shape[0]):\n",
    "#     edge = edge_index.T[i]\n",
    "#     if edge[0] < edge[1]:\n",
    "#         edge_index_temp.append(edge)\n",
    "#         edge_attr_temp.append(edge_attr[i])\n",
    "# edge_attr = np.array(edge_attr_temp)\n",
    "# edge_index = np.array(edge_index_temp).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "50f0d755-c14a-41fa-b95d-a8aa2f7ae688",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_tr = feats_tr.reshape(-1,8,768)\n",
    "feats_tr = feats_tr[:,1:,:].reshape(-1,7*768)\n",
    "feats_te_avg = feats_te_avg.reshape(-1,8,768)\n",
    "feats_te_avg = feats_te_avg[:,1:,:].reshape(-1,7*768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f4f25828-7ea9-4457-b6cb-3ec942423295",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trial_tr, num_trials_te = feats_tr.shape[0], feats_te_avg.shape[0]\n",
    "\n",
    "train_dataset = []\n",
    "\n",
    "for i in range(num_trial_tr):\n",
    "    train_dataset.append(Data(x=torch.tensor(betas_tr.reshape(-1, num_roi, num_neurons_each_roi)[i], dtype=torch.float), \n",
    "            edge_index=torch.tensor(edge_index, dtype=torch.long), \n",
    "            edge_attr=torch.tensor(edge_attr, dtype=torch.float),\n",
    "            y=torch.tensor(feats_tr[i], dtype=torch.float)\n",
    "            ))\n",
    "    \n",
    "test_dataset = []\n",
    "for i in range(num_trials_te):\n",
    "    test_dataset.append(Data(x=torch.tensor(betas_te_avg.reshape(-1, num_roi, num_neurons_each_roi)[i], dtype=torch.float), \n",
    "            edge_index=torch.tensor(edge_index, dtype=torch.long), \n",
    "            edge_attr=torch.tensor(edge_attr, dtype=torch.float),\n",
    "            y=torch.tensor(feats_te_avg[i], dtype=torch.float)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6d9ccb50-2100-4f12-85ab-a6574fe1ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a260773a-2399-4bab-974c-e8bb3c0157a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[16, 1574], edge_index=[2, 22], edge_attr=[22], y=[5376]),\n",
       " Data(x=[16, 1574], edge_index=[2, 22], edge_attr=[22], y=[5376]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0], test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "30340b2e-eda2-419a-9c95-cab33a658b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv, TopKPooling, BatchNorm,ChebConv, SAGEConv,GATConv\n",
    "from torch_geometric.nn import global_mean_pool, global_max_pool,global_add_pool\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, num_neurons_each_roi):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = ChebConv(num_neurons_each_roi, 512, K=4)\n",
    "\n",
    "        self.conv = ChebConv(512, 512, K=3)\n",
    "        self.bn = BatchNorm(512)\n",
    "\n",
    "        nnconv_channel = 4\n",
    "        self.nnconv = nn.Sequential(\n",
    "            nn.Conv1d(1, nnconv_channel, kernel_size=1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(nnconv_channel, nnconv_channel, kernel_size=3, padding = 1),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.downsample = nn.Conv1d(nnconv_channel, 1, kernel_size=1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 7*768)\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch,edge_attr = data.x, data.edge_index, data.batch, data.edge_attr\n",
    "        batch_size = batch.max() + 1\n",
    "\n",
    "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "        \n",
    "        for i in range(1):\n",
    "            a = self.conv(x, edge_index, edge_attr)\n",
    "            a = self.bn(a)\n",
    "            x = x + F.leaky_relu(a)\n",
    "        \n",
    "        x = global_mean_pool(x, batch) # print(x.shape) torch.Size([64, 256])\n",
    "\n",
    "        x = x.unsqueeze(1)\n",
    "        # x = self.nnconv(x)\n",
    "        # for j in range(2):\n",
    "        #     x = x + self.net(x)\n",
    "        # x = self.downsample(x)\n",
    "        x = x.flatten(start_dim=1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d384c6ee-d896-4123-8399-4cf133d33d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 0] train loss 0.76835 val loss 0.69196\n",
      "[epoch 1] train loss 0.68776 val loss 0.69045\n",
      "[epoch 2] train loss 0.686 val loss 0.68925\n",
      "[epoch 3] train loss 0.68339 val loss 0.68794\n",
      "[epoch 4] train loss 0.67789 val loss 0.68769\n",
      "[epoch 5] train loss 0.66863 val loss 0.68519\n",
      "[epoch 6] train loss 0.65451 val loss 0.68561\n",
      "[epoch 7] train loss 0.63741 val loss 0.6892\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[184], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_dataloader:\n\u001b[0;32m---> 16\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     batch_num \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mbatch\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m     feats \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(batch_num,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/hdd/yuchen/anaconda3/envs/ldm/lib/python3.8/site-packages/torch_geometric/data/data.py:297\u001b[0m, in \u001b[0;36mBaseData.to\u001b[0;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    294\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hdd/yuchen/anaconda3/envs/ldm/lib/python3.8/site-packages/torch_geometric/data/data.py:280\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[0;32m--> 280\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/hdd/yuchen/anaconda3/envs/ldm/lib/python3.8/site-packages/torch_geometric/data/storage.py:191\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[0;34m(self, func, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/hdd/yuchen/anaconda3/envs/ldm/lib/python3.8/site-packages/torch_geometric/data/storage.py:743\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[0;34m(data, func)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m--> 743\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[1;32m    745\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[0;32m/hdd/yuchen/anaconda3/envs/ldm/lib/python3.8/site-packages/torch_geometric/data/data.py:298\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    294\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    295\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m--> 298\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = 'cuda:1'\n",
    "model = GNN(num_neurons_each_roi=num_neurons_each_roi).to(device)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 100\n",
    "patience = 5\n",
    "ct = 0\n",
    "best_loss_val = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss_train = 0\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        batch_num = batch.batch.max() + 1\n",
    "        feats = batch['y'].reshape(batch_num,-1).to(device)\n",
    "        pred = model(batch)\n",
    "        \n",
    "        loss = loss_fn(pred, feats)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss_train += loss.item()\n",
    "    print('[epoch {}] train loss {}'.format(epoch, round(total_loss_train/len(train_dataloader), 5)), end = ' ')\n",
    "\n",
    "    model.eval()\n",
    "    total_loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            batch = batch.to(device)\n",
    "            batch_num = batch.batch.max() + 1\n",
    "            feats = batch['y'].reshape(batch_num,-1).to(device)\n",
    "            pred = model(batch)\n",
    "            loss = loss_fn(pred, feats)\n",
    "            total_loss_val += loss.item()\n",
    "        total_loss_val = total_loss_val/len(test_dataloader)\n",
    "        print('val loss {}'.format(round(total_loss_val, 5)))\n",
    "        \n",
    "        if total_loss_val < best_loss_val:\n",
    "            ct = 0\n",
    "            best_loss_val = total_loss_val\n",
    "            torch.save(model.state_dict(), '/hdd/yuchen/modelweights_things_text_gcn_roi.pth')\n",
    "        else:\n",
    "            ct += 1\n",
    "            if ct > patience:\n",
    "                print('end')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56ce0ac-5d59-4d1f-8129-86f1cfbf9045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a61a0-b448-4e5a-8385-d1f5f60369fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
